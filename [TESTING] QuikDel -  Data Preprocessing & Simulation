{"cells":[{"cell_type":"markdown","metadata":{"id":"92hKI7TG3Mv9"},"source":["# QuikDel Simulation\n"]},{"cell_type":"markdown","metadata":{"id":"boK7DL5n3PIB"},"source":["## Imports"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1746194730602,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"},"user_tz":240},"id":"GpE2PJh23CqY"},"outputs":[],"source":["import geopandas as gpd\n","from shapely.geometry import Point\n","import random\n","import numpy as np\n","import pandas as pd\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from google.colab import drive\n","import os\n","import time as t\n","import heapq\n","import json\n","import sys\n","import matplotlib.colors as mcolors\n","import matplotlib.lines as mlines\n","import ast\n","import requests\n","from geopy.distance import geodesic\n","import pickle\n","from shapely.geometry import shape\n","from collections import defaultdict\n","\n","## MOST LIKELY NOT USE THESE\n","# !pip install memory-profiler\n","# !pip install psutil\n","# from memory_profiler import memory_usage\n","# import psutil"]},{"cell_type":"markdown","metadata":{"id":"sMczv4MS3TMr"},"source":["## Variables"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1746194735585,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"},"user_tz":240},"id":"KKmfm7WA3WOE"},"outputs":[],"source":["# City Data\n","city_name = \"City of New York\"\n","mini = False"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":37,"status":"ok","timestamp":1746194735623,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"},"user_tz":240},"id":"_rMeRiDg3UGf"},"outputs":[],"source":["# Ratio data\n","superspot_hotspot_ratio = 15\n","min_children = superspot_hotspot_ratio - 3"]},{"cell_type":"markdown","metadata":{"id":"bE4XTWod3ZU6"},"source":["## Directory Setup\n","In Colab, we connect to Google Drive."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2248,"status":"ok","timestamp":1746194738603,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"},"user_tz":240},"id":"OyO9tFM_3eeU","outputId":"2a6f49f4-e509-4cf4-cb1e-3cc84b24706c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n","Files in directory :  ['Original Location Data', 'Processed Location Data', 'Census Data', 'Images', 'Hotspot Data', 'avg_hotspot_data.json', 'Q Tables', 'Results', 'Deliveries']\n"]}],"source":["drive.mount('/content/gdrive/', force_remount=True)\n","personal_dir = \"./gdrive/MyDrive/DeliverAI Data Folder/\"\n","data_dir = f\"{personal_dir}{city_name}_mini - RL Delivery Data\" if mini else f\"{personal_dir}{city_name} - RL Delivery Data\"\n","\n","# See directory content\n","data = os.listdir(data_dir)\n","print(\"Files in directory : \", data)"]},{"cell_type":"markdown","metadata":{"id":"Sq2cgAse3him"},"source":["## Load Data"]},{"cell_type":"markdown","metadata":{"id":"CKJ_-TJt3plR"},"source":["#### Loading city data"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":3212,"status":"ok","timestamp":1746194741815,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"},"user_tz":240},"id":"dP18UA9P3lWK"},"outputs":[],"source":["census_df = gpd.read_file(data_dir + \"/Census Data/census_tract_data.geojson\")\n","\n","distance_matrix = np.load(data_dir + f\"/Hotspot Data/Data-{min_children}-{superspot_hotspot_ratio}/distance_adjacency_matrix.npy\")\n","time_matrix = np.load(data_dir + f\"/Hotspot Data/Data-{min_children}-{superspot_hotspot_ratio}/time_adjacency_matrix.npy\")\n","\n","gh_df = pd.read_csv(data_dir + f'/Hotspot Data/Data-{min_children}-{superspot_hotspot_ratio}/graphhopper_dataframe.csv', dtype={'GEOID': 'string'}).drop([\"Unnamed: 0\"], axis=1)\n","num_hotspots = len(census_df.index)"]},{"cell_type":"markdown","metadata":{"id":"gX5LGvtp3vGY"},"source":["#### Loading Q-Table data"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":3491,"status":"ok","timestamp":1746194745313,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"},"user_tz":240},"id":"vJjdQ3KW3u3z"},"outputs":[],"source":["def convert_str_to_int(d):\n","  return {int(k) if k.isdigit() else k: int(v) if isinstance(v, str) and v.isdigit() else v for k, v in d.items()}\n","\n","with open(data_dir + \"/Hotspot Data/map_geoid_index.json\", 'r') as f:\n","    tract_to_index = json.load(f)\n","index_to_tract = {v: k for k, v in tract_to_index.items()}\n","\n","with open(data_dir + f\"/Q Tables/Data-{min_children}-{superspot_hotspot_ratio}/index_to_Q.json\", 'r') as f:\n","  index_to_Q = convert_str_to_int(json.load(f))\n","\n","with open(data_dir + f\"/Q Tables/Data-{min_children}-{superspot_hotspot_ratio}/Q_to_index.json\", 'r') as f:\n","  Q_to_index = convert_str_to_int(json.load(f))\n","\n","  for k, v in Q_to_index.items():\n","    Q_to_index[k] = convert_str_to_int(v)\n","\n","with open(data_dir + f\"/Q Tables/Data-{min_children}-{superspot_hotspot_ratio}/index_to_Q_super.json\", 'r') as f:\n","  index_to_Q_super = convert_str_to_int(json.load(f))\n","\n","with open(data_dir + f\"/Q Tables/Data-{min_children}-{superspot_hotspot_ratio}/Q_super_to_index.json\", 'r') as f:\n","  Q_super_to_index = convert_str_to_int(json.load(f))\n","\n","with open(data_dir + f\"/Q Tables/Data-{min_children}-{superspot_hotspot_ratio}/tract_group_lists.json\", 'r') as f:\n","  tract_group_lists = convert_str_to_int(json.load(f))\n","  tract_group_lists[-1] = tract_group_lists['-1']\n","  del tract_group_lists['-1']\n","\n","with open(data_dir + f\"/Q Tables/Data-{min_children}-{superspot_hotspot_ratio}/tract_super_dict.json\", 'r') as f:\n","  tract_super_dict = convert_str_to_int(json.load(f))\n","\n","Q_tables = np.load(data_dir + f\"/Q Tables/Data-{min_children}-{superspot_hotspot_ratio}/Q_boltzman.npz\", allow_pickle=True)\n","Q_tables = {int(key): Q_tables[key] for key in Q_tables}"]},{"cell_type":"markdown","metadata":{"id":"CScjECG34XqS"},"source":["#### Creating Full/\"Estimate\" Distance and Time matrices\n","**Note:** The Estimate matrices will only be created if they do not already exist."]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":4187,"status":"ok","timestamp":1746194749502,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"},"user_tz":240},"id":"rQ3FozYY4daR"},"outputs":[],"source":["if \"estimate_distance_adjacency_matrix.npy\" not in os.listdir(data_dir + \"/Hotspot Data\") or \"estimate_time_adjacency_matrix.npy\" not in os.listdir(data_dir + \"/Hotspot Data\"):\n","  # Import hotspots and order according to tract_to_index\n","  hotspot_df = gpd.read_file(data_dir + \"/Hotspot Data/hotspot_data.geojson\")\n","  hotspot_df['index_order'] = hotspot_df['GEOID'].map(tract_to_index)\n","  hotspot_df = hotspot_df.sort_values(by='index_order').reset_index(drop=True)\n","  hotspot_df = hotspot_df.drop(columns=['index_order'])\n","\n","\n","  # Turn hotspot dataframe into a matrix of coordinates getting the distance between them\n","  coords = hotspot_df['geometry'].apply(lambda geom: (geom.x, geom.y)).tolist()\n","  estimate_dist_matrix = np.zeros((len(coords), len(coords)))\n","\n","  # Calculate pairwise geodesic distances\n","  for i, coord1 in enumerate(coords):\n","    for j, coord2 in enumerate(coords):\n","      estimate_dist_matrix[i, j] = geodesic(coord1, coord2).meters if i != j else 0.0\n","\n","  # Add the average distance longer that actual roads take to the crow-flies distances\n","  dist_diff_matrix = distance_matrix - estimate_dist_matrix\n","  dist_diff_matrix = dist_diff_matrix[dist_diff_matrix < 100000000]\n","  avg_increase = dist_diff_matrix.mean()\n","  estimate_dist_matrix = estimate_dist_matrix + avg_increase\n","\n","  # Get the speed of the distances from the distance/time matrices\n","  speed_matrix = distance_matrix / time_matrix\n","  np.nan_to_num(speed_matrix, 0)  # Set nan values to 0\n","\n","  # Exclude values where speed is 1, as the vast majority (if not all) indicate edges that dont exist\n","  valid_speeds_mask = (speed_matrix != 1) & ~np.isnan(speed_matrix)\n","\n","  # Mask speed matrix\n","  valid_speeds = speed_matrix[valid_speeds_mask]\n","  average_speed = np.mean(valid_speeds) # Get the mean of the matrix, this gives the average speed for each distance travelled\n","\n","  estimate_time_matrix = estimate_dist_matrix / average_speed  # Use this and the full distance matrix to create the full time matrix\n","\n","  np.save(data_dir + f\"/Hotspot Data/estimate_distance_adjacency_matrix.npy\", estimate_dist_matrix)\n","  np.save(data_dir + f\"/Hotspot Data/estimate_time_adjacency_matrix.npy\", estimate_time_matrix)\n","\n","estimate_dist_matrix = np.load(data_dir + f\"/Hotspot Data/estimate_distance_adjacency_matrix.npy\")\n","estimate_time_matrix = np.load(data_dir + f\"/Hotspot Data/estimate_time_adjacency_matrix.npy\")"]},{"cell_type":"markdown","metadata":{"id":"qcwXTeft43zy"},"source":["Below the full distance/time matrices are created and updated as necessary"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5392,"status":"ok","timestamp":1746194754896,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"},"user_tz":240},"id":"ysZLoMlp45qs","outputId":"8392dd74-ad15-48f0-b451-c210fdcb968c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Already exist\n"]}],"source":["if \"full_distance_adjacency_matrix.npy\" not in os.listdir(data_dir + \"/Hotspot Data\") or \"full_time_adjacency_matrix.npy\" not in os.listdir(data_dir + \"/Hotspot Data\"):\n","  print(\"Creating new\")\n","  full_dist_matrix = distance_matrix\n","  full_time_matrix = time_matrix\n","\n","  np.save(data_dir + f\"/Hotspot Data/full_distance_adjacency_matrix.npy\", distance_matrix)\n","  np.save(data_dir + f\"/Hotspot Data/full_time_adjacency_matrix.npy\", time_matrix)\n","\n","else:\n","  print(\"Already exist\")\n","  full_dist_matrix = np.load(data_dir + f\"/Hotspot Data/full_distance_adjacency_matrix.npy\")\n","  full_time_matrix = np.load(data_dir + f\"/Hotspot Data/full_time_adjacency_matrix.npy\")\n","\n","  # Copy distance/time_matrix data onto full, and save it again.\n","  for i in range(len(census_df.index)):\n","    for j in range(len(census_df.index)):\n","      if full_dist_matrix[i, j] == sys.maxsize and distance_matrix[i, j] != sys.maxsize:\n","        full_dist_matrix[i, j] = distance_matrix[i, j]\n","        full_time_matrix[i, j] = time_matrix[i, j]\n","\n","  np.save(data_dir + f\"/Hotspot Data/full_distance_adjacency_matrix.npy\", full_dist_matrix)\n","  np.save(data_dir + f\"/Hotspot Data/full_time_adjacency_matrix.npy\", full_time_matrix)"]},{"cell_type":"markdown","metadata":{"id":"4ETwlC0U31_M"},"source":["\n","## Simulation Materials"]},{"cell_type":"markdown","metadata":{"id":"ZeHtsJvN3_yK"},"source":["#### Global Variables and Functions"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1746194756903,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"},"user_tz":240},"id":"P9FS-kF93_Zl"},"outputs":[],"source":["INTERVALS = [900, 1200, 1500, 1800, 2700, 3600, 5400, 7200, 10800, 14400]"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45,"status":"ok","timestamp":1746194756948,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"},"user_tz":240},"id":"st1mpu8jOUW6","outputId":"fc874200-f99e-4f21-eaaf-67bdc8eee51b"},"outputs":[{"output_type":"stream","name":"stdout","text":["./gdrive/MyDrive/DeliverAI Data Folder/City of New York - RL Delivery Data/Deliveries Already Exists\n"]}],"source":["# Changed the directory\n","deliveries_dir = data_dir + f\"/Deliveries\"\n","try:\n","  os.mkdir(deliveries_dir)\n","except:\n","  print(deliveries_dir + \" Already Exists\")"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":0,"status":"ok","timestamp":1746194756949,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"},"user_tz":240},"id":"sDW40x2gMwtX"},"outputs":[],"source":["def write_to_full_matrix(start_node, end_node):\n","  if full_dist_matrix[start_node][end_node] == sys.maxsize or full_time_matrix[start_node][end_node] == sys.maxsize:\n","    from_row = gh_df[gh_df['GEOID'] == index_to_tract[start_node]]\n","    from_points = [[ from_row['x'].values[0], from_row['y'].values[0] ]]\n","\n","    to_row = gh_df[gh_df['GEOID'] == index_to_tract[end_node]]\n","    to_points = [[ to_row['x'].values[0], to_row['y'].values[0] ]]\n","\n","    gh_data = gh_query(from_points, to_points, keys)\n","\n","    full_dist_matrix[start_node, end_node] = gh_data['distances'][0][0]\n","    full_time_matrix[start_node, end_node] = gh_data['times'][0][0]\n","\n","    # print(f\"Updated {start_node} to {end_node} with {gh_data['distances'][0][0]}\")\n","\n","    np.save(data_dir + f\"/Hotspot Data/full_time_adjacency_matrix.npy\", full_time_matrix)\n","    np.save(data_dir + f\"/Hotspot Data/full_distance_adjacency_matrix.npy\", full_dist_matrix)\n","\n","\n","\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', None)\n","pd.set_option('display.width', 500)\n","pd.set_option('display.colheader_justify', 'center')\n","pd.set_option('display.precision', 2)\n","\n","def print_matrix(matrix):\n","    modified_matrix = np.where(matrix > 1000000, -1, matrix)\n","\n","    index_labels = [index_to_tract[i][-4:] for i in range(len(matrix))]  # Setting row labels\n","    columns_labels = [index_to_tract[i][-4:] for i in range(len(matrix))]  # Setting col labels\n","\n","    print(pd.DataFrame(modified_matrix, columns=columns_labels, index=index_labels))\n"]},{"cell_type":"markdown","metadata":{"id":"5VGcNqNjTMyz"},"source":["##### Graphhopper Setup"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":35,"status":"ok","timestamp":1746194756985,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"},"user_tz":240},"id":"EVGtaUVATOdS"},"outputs":[],"source":["keys = [\n","  '7099ca3b-a0f7-4aaf-b5c6-843fa561328f',\n","  'e15ce7ad-4d2f-4a1d-a0bd-5c6abbd6f5d6',\n","  '7e555d35-8fa2-44cd-bcd4-d8ae7b38a256'\n","]\n","\n","\n","key_ind = len(keys)-1  # Index in the list that determines which key is being used. Starts from last and works its way up because I feel cool when I do it that way\n","\n","URL = \"https://graphhopper.com/api/1/matrix\"  # GraphHopper matrix API url\n","req_lim = 80  # Limit on number of requests in one go\n","\n","# Generates GraphHopper query using provided params\n","def gh_query(from_point, to_point, keys: list):\n","  global key_ind\n","\n","  # Do-while loop in python, runs query before checking\n","  while True:\n","    # Query to provide the key\n","    query = { \"key\": keys[key_ind] }\n","\n","    # Payload to send rest of data\n","    payload = {\n","        \"profile\": \"car\",\n","        \"from_points\": from_point,\n","        \"to_points\": to_point,\n","        \"out_arrays\": [\"distances\",\"times\"],\n","        \"fail_fast\": \"true\",\n","    }\n","\n","    # Get response using POST\n","    response = requests.post(URL, json=payload, params=query)\n","    data = response.json()  # Store data as json\n","\n","    # If there is a message, then something went wrong.\n","    if 'message' not in data.keys():\n","      return data  # No message so return data\n","    else:  # Assume message says key ran out\n","      if key_ind > 0:  # Make sure we don't exit bounds of list\n","        key_ind -= 1\n","      else:  # Otherwise we have run out of keys\n","        if 'Minutely API limit heavily violated' not in data['message']:\n","          print(data['message'])\n","        key_ind = len(keys)-1\n","\n","  return None  # Function shouldn't reach this but it's here just in case since the only other return is in an if-statement"]},{"cell_type":"markdown","metadata":{"id":"923vw6At4F8Y"},"source":["### Deliveries"]},{"cell_type":"markdown","metadata":{"id":"IQesG3xg-wwV"},"source":["#### Delivery Class"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1746194756989,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"},"user_tz":240},"id":"Q8wumzRD4JXc"},"outputs":[],"source":["class Delivery:\n","  id = 0\n","  def __init__(self, start_node, end_node, start_time, percent):\n","    # IMMUTABLE\n","    self.id = Delivery.id\n","    Delivery.id += 1\n","    self.start_node = start_node\n","    self.end_node = end_node\n","    self.start_time = start_time\n","\n","\n","    # MUTABLE\n","    self.current_node = self.start_node\n","    self.time_till_next_node = 0\n","    self.end_time = None\n","    self.in_transition = False\n","    self.is_primary = True\n","    self.next_node = None\n","    self.sharing_node = None\n","    self.completed = False\n","    self.successful = False\n","    self.num_car_changes = 2  # For initial change from PDC to CDV and for the final change to CDV to PDC\n","    self.sharing_with = None\n","    self.path = [self.start_node]\n","    self.distance_traveled = 0\n","    self.percent_max_dist = percent\n","    self.step = self.set_step()  # Make sure this is initialized before time_limit for dependency reasons\n","    self.time_limit = self.calculate_time_limit()\n","\n","    # DEBUG VARIABLES (also mutable)\n","    self.did_share = False\n","    self.shared_with_final = None\n","    self.shared_with_when = None\n","\n","\n","  def calculate_time_limit(self):\n","    global INTERVALS\n","\n","    path_time = full_time_matrix[self.start_node, self.end_node]\n","\n","    for interval in INTERVALS:\n","      if path_time * 1.5 <= interval:\n","        return interval\n","    return float('inf')  # Realistically no delivery should reach this point.\n","\n","\n","  def check_direct_share(self):\n","    # Are census tracts in different groups?\n","    different_groups = tract_super_dict[self.start_node] != tract_super_dict[self.end_node]\n","\n","\n","    # Are the hotspots close enough for direct delivery?\n","    max_distance = max(\n","      np.max(estimate_dist_matrix),\n","      np.max(full_dist_matrix[full_dist_matrix != sys.maxsize]))\n","\n","    close_proximity = full_dist_matrix[self.start_node, self.end_node] / max_distance <=  self.percent_max_dist / 100\n","\n","\n","    # Is the max sharing distance indended to be NEVER?\n","    never_share = self.percent_max_dist == 100\n","\n","\n","    # Must be ( in different groups AND close enough )  OR;\n","    #  maximum percentage of max distance travel == 100 (AKA do not share for all deliveries)\n","    return ( different_groups and close_proximity ) or never_share\n","\n","  def set_step(self):\n","    ## GUIDE to STEPS:\n","    # - Step 1: Delivery is in sub-group, must travel to super-spot to reach destination.\n","    # - Step 2: Delivery is in super-spot level, must travel to next super-spot to reach destination.\n","    # - Step 3: Delivery is in sub-group, must travel to destination within the same group.\n","    # - Step 4: Delivery will travel directly from start to finish with no sharing potential.\n","\n","    if self.check_direct_share():\n","      step_val = 4\n","    elif tract_super_dict[self.start_node] == tract_super_dict[self.end_node]:\n","      step_val = 3\n","    elif tract_super_dict[self.start_node] != tract_super_dict[self.end_node] and tract_super_dict[self.start_node] == self.start_node:\n","      step_val = 2\n","    else:\n","      step_val = 1\n","\n","    return step_val\n","\n","  def reset(self, p=-1):\n","    percent = self.percent_max_dist if p < 0 else p\n","\n","    self.current_node = self.start_node\n","    self.time_till_next_node = 0\n","    self.end_time = None\n","    self.in_transition = False\n","    self.is_primary = True\n","    self.next_node = None\n","    self.sharing_node = None\n","    self.completed = False\n","    self.successful = False\n","    self.num_car_changes = 2\n","    self.sharing_with = None\n","    self.path = [self.start_node]\n","    self.distance_traveled = 0\n","    self.percent_max_dist = percent\n","    self.step = self.set_step()  # Make sure this is initialized before time_limit for dependency reasons\n","    self.time_limit = self.calculate_time_limit()\n","\n","    # DEBUG VARIABLES\n","    self.did_share = False\n","    self.shared_with_final = None\n","    self.shared_with_when = None\n","\n","\n","  # How to determine delivery1 < delivery2\n","  def __lt__(self, other):\n","    # Compare start times\n","    if self.start_time != other.start_time:\n","      return self.start_time < other.start_time\n","    # Compare path lengths\n","    elif len(self.path) != len(other.path):\n","      return len(self.path) < len(other.path)\n","    # ID failsafe\n","    else:\n","      return self.id < other.id\n","\n","  def __str__(self):\n","    return f\"Delivery {self.id}\\n\" \\\n","           f\"Start Time: \\t {self.start_time}\\n\" \\\n","           f\"Start Hotspot: \\t {self.start_node}\\n\" \\\n","           f\"End Hotspot: \\t {self.end_node}\\n\" \\\n","           f\"In Transition: \\t {self.in_transition}\\n\" \\\n","           f\"Time limit: \\t {self.time_limit}\\n\" \\\n","           f\"Time left: \\t {self.time_till_next_node}\\n\" \\\n","           f\"Current Hotspot: {self.current_node}\\n\" \\\n","           f\"Next Hotspot: \\t {self.next_node}\\n\" \\\n","           f\"Step: \\t {self.step}\\n\" \\\n","           f\"Sharing With: \\t {self.sharing_with.id if self.sharing_with is not None else None} \\n\" \\\n","           f\"Shared With Final: \\t {self.shared_with_final} \\n\" \\\n","           f\"Shared With When: \\t {self.shared_with_when} \\n\" \\\n","           f\"Path: \\t \\t {self.path}\\n\" \\\n","           f\"Completed: \\t {self.completed}\\n\""]},{"cell_type":"markdown","metadata":{"id":"FqnRWfG4-qFd"},"source":["#### DeliveryList Class"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1746194757023,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"},"user_tz":240},"id":"0FQTnlMI-3Zj"},"outputs":[],"source":["import copy  # Necessary to allow for deep copy creation\n","\n","class DeliveryList:\n","  # distance_based = further, closer, <anything else for random>\n","  def __init__(self, distance_based:str, load:int, percent_max_dist:float, hours:int=1, peaks:list=[0.25, 0.75], sigma:float=10, gen_multi:bool=False, use_generated_paths:bool=False):\n","    self.distance_based = distance_based\n","    self.load = load\n","    self.hours = hours\n","    self.peaks = peaks\n","    self.sigma = sigma\n","    self.percent_max_dist = percent_max_dist\n","    self.gen_multi = gen_multi\n","    print(\"Generating ID...\")\n","    self.id = DeliveryList.gen_deliveries_id(distance_based=self.distance_based, load=self.load, percent_max_dist=self.percent_max_dist,\n","                                             hours=self.hours, peaks=self.peaks, sigma=self.sigma, gen_multi=self.gen_multi)\n","    print(\"done.\\n\\nGenerating distribution...\")\n","    self.distribution, self.loads = self.generate_distribution()\n","    print(\"done.\\n\\nGenerating deliveries...\")\n","    self.deliveries = self.generate_deliveries(use_generated_paths)\n","    print(\"\\ndone.\\n\\nSaving deliveries...\")\n","    DeliveryList.save_deliveries(self)\n","    print(\"done.\")\n","\n","\n","  # Function to generate delivery ID\n","  @staticmethod\n","  def gen_deliveries_id(distance_based:str, load:int, percent_max_dist:float, hours:int=1, peaks:list=[0.25, 0.75], sigma:float=10, gen_multi:bool=False, multi_id:int=0):\n","    global deliveries_dir\n","\n","    if not gen_multi and multi_id > 0:\n","      raise ValueError(\"gen_multi must be True if multi_id is specified.\")\n","\n","    # Determine distance-based id\n","    match distance_based:\n","      case \"further\":\n","        base_code = \"1\"\n","      case \"closer\":\n","        base_code = \"2\"\n","      case \"one_cluster\":\n","        base_code = \"3\"\n","      case _:\n","        base_code = \"0\"\n","\n","    # Construct initial id_str\n","    id_str = (\n","      f\"{base_code}\"\n","      f\"-{load:04d}\"\n","      f\"-{hours:03d}\"\n","      f\"-{sigma:03d}\"\n","      f\"-{peaks}\"\n","      f\"-{percent_max_dist:03d}\"\n","    )\n","\n","\n","    # List of already matching IDs\n","    list_matching_ids = [f for f in os.listdir(deliveries_dir) if f.startswith(id_str)] if gen_multi else []\n","\n","    # The final id will be stored here\n","    final_id = id_str\n","\n","    # If multi_id was specified\n","    if multi_id > 0:\n","      final_multi_id = multi_id-1\n","    # If the list is not empty:\n","    elif list_matching_ids:\n","      # multi_ids is a list of the terminating multi id number at the\n","      #   end of each of the ids\n","      multi_ids = (\n","        int(f.split('-')[-1])\n","        for f in list_matching_ids\n","        if '[' not in f.split('-')[-2] and f.split('-')[-1].isdigit()\n","      )\n","\n","      # Determine the maximum multi-ID\n","      final_multi_id = max(multi_ids, default=0)\n","    else:\n","      return final_id\n","\n","    # Update final_id based on max_multi_id\n","    final_id += f'-{final_multi_id + 1:02d}' if final_multi_id else '-01'\n","\n","    return final_id\n","\n","\n","  # Function to generate distribution\n","  def generate_distribution(self):\n","    # mu for each peak\n","    mu_list = [peak * 60 * self.hours for peak in self.peaks]\n","\n","    # x vals (one x value per minute)\n","    x = np.linspace(0, 60 * self.hours, 60 * self.hours)\n","\n","    # Create individual normal distributions and sum them\n","    y_combined = np.zeros_like(x)  # Numpy array of 0's of len(x)\n","    for mu in mu_list:\n","      y_combined += (1 / (self.sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / self.sigma) ** 2)  # Performs distribution operation across array of x\n","\n","    # Convert distribution into loads\n","    loads = [int((self.load * (self.sigma * np.sqrt(2 * np.pi))) * y) for y in y_combined]\n","\n","    # IMPORTANT! What to return?\n","    return y_combined, loads\n","\n","\n","  def generate_deliveries(self, use_generated_paths:bool=False):\n","    with open(data_dir + \"/avg_hotspot_data.json\") as f:\n","      hotspot_data = json.load(f)\n","\n","    valid_hotspots = [i for i in range(num_hotspots) if index_to_tract[i] in hotspot_data and hotspot_data[index_to_tract[i]][\"distance\"] != 0]\n","\n","    deliveries = []\n","    with tqdm(total=sum(self.loads)) as pbar:\n","      for j in range(60*self.hours):  # For each minute\n","        for _ in range(self.loads[j]):\n","          while True:\n","            start = random.choice(valid_hotspots)\n","            end = random.choice(valid_hotspots)\n","\n","            if use_generated_paths and full_time_matrix[start, end] == sys.maxsize:\n","              continue\n","\n","            max_dist = max(\n","              np.max(estimate_dist_matrix),\n","              np.max(full_dist_matrix[full_dist_matrix != sys.maxsize]))\n","            tot = (estimate_dist_matrix[start][end] / max_dist)\n","\n","            st_ed_eq = start != end\n","\n","            if self.distance_based == \"further\":\n","              rand = random.uniform(0.10, 0.85)\n","              if tot > rand and st_ed_eq:\n","                break\n","            elif self.distance_based == \"closer\":\n","              rand = random.uniform(0.10, 1)\n","              if tot < rand and st_ed_eq:\n","                break\n","            else:\n","              if st_ed_eq:\n","                break\n","\n","          # Generate time and delivery object\n","          time = random.randint(j * 60, (j + 1) * 60)  # Random second in the minute\n","          write_to_full_matrix(start, end)\n","\n","          temp_delivery = Delivery(start, end, time, self.percent_max_dist)\n","          deliveries.append(temp_delivery)\n","          pbar.update(1)\n","\n","    return deliveries\n","\n","\n","  # Function to save\n","  @staticmethod\n","  def save_deliveries(deliverylist, graph:bool=False):\n","    if not isinstance(deliverylist, DeliveryList):\n","      raise TypeError(\"Parameter deliverylist must be of type DeliveryList.\")\n","\n","    temp_dir = deliveries_dir\n","\n","    if graph:\n","      temp_dir += \"/Graphing\"\n","      try:\n","        os.mkdir(temp_dir)\n","      except:\n","        pass\n","\n","    deliveries_id = deliverylist.id\n","    if not graph:\n","      print(\"Saving to\", temp_dir + f\"/{deliveries_id}\")\n","    with open(temp_dir + f\"/{deliveries_id}\", 'wb') as file:\n","      pickle.dump(deliverylist, file)\n","\n","\n","  # Function to load\n","  @staticmethod\n","  def load_deliveries(deliveries_id:str, graph:bool=False):\n","    temp_dir = deliveries_dir\n","\n","    if graph:\n","      temp_dir += \"/Graphing\"\n","      try:\n","        os.mkdir(temp_dir)\n","      except:\n","        pass\n","\n","    if not graph:\n","      print(\"Loading from\", temp_dir + f\"/{deliveries_id}\")\n","    with open(temp_dir + f\"/{deliveries_id}\", 'rb') as file:\n","      deliveries = pickle.load(file)\n","\n","    return deliveries\n","\n","\n","  # Function to reset all\n","  def reset_deliveries(self, percent_max_dist:float=-1):\n","    for d in self.deliveries:\n","      d.reset(percent_max_dist)\n","\n","    self.percent_max_dist = percent_max_dist if percent_max_dist >= 0 else self.percent_max_dist\n","    self.id = DeliveryList.gen_deliveries_id(distance_based=self.distance_based, load=self.load, percent_max_dist=self.percent_max_dist,\n","      hours=self.hours, peaks=self.peaks, sigma=self.sigma, gen_multi=self.gen_multi)\n","\n","  # Create and return a deep copy of self (completely independent of original)\n","  def copy(self):\n","    return copy.deepcopy(self)\n","\n","\n","  ## Functions to show various graphs below\n","  def plot_base_distribution(self):\n","    plt.scatter(y=self.distribution, x=list(range(len(self.distribution))), color=\"green\")\n","    plt.title('Plot of Delivery Peaks Distribution')\n","    plt.xlabel('Time (minutes)')\n","    plt.ylabel('Weight')\n","    plt.show()\n","\n","  def plot_load_distribution(self):\n","    plt.scatter(y=self.loads, x=list(range(len(self.loads))), color=\"green\")\n","    plt.title('Plot of Delivery Load Distribution')\n","    plt.xlabel('Time (minutes)')\n","    plt.ylabel('Weight')\n","    plt.show()\n","\n","  def plot_starttime_distribution(self):\n","    starttime_lst = [d.start_time for d in self.deliveries]\n","    plt.hist(starttime_lst, bins=10, color=\"lightgreen\", edgecolor='grey', alpha=0.7)\n","    plt.title('Histogram of Delivery Starting Time')\n","    plt.xlabel('Distance (meters)')\n","    plt.ylabel('Frequency')\n","    plt.show()\n","\n","  def plot_distance_distribution(self):\n","    distances = [full_dist_matrix[d.start_node][d.end_node] for d in self.deliveries]\n","\n","    print(\"Average: \", np.mean(distances))\n","    plt.hist(distances, bins=10, color=\"lightgreen\", edgecolor='grey', alpha=0.7)\n","    plt.title('Histogram of Delivery Distance')\n","    plt.xlabel('Value')\n","    plt.ylabel('Frequency')\n","    plt.show()\n","\n","  def plot_time_limits(self):\n","    d_limits = [d.time_limit for d in self.deliveries]\n","    d_base_times = [full_time_matrix[d.start_node, d.end_node] for d in self.deliveries]\n","    d_limits.sort()\n","    d_base_times.sort()\n","    plt.scatter(y=d_limits, x=list(range(len(self.deliveries))), label='Time Limit', color=\"darkgreen\")\n","    plt.scatter(y=d_base_times, x=list(range(len(d_base_times))), label='Direct Travel Time', color=\"lightgreen\")\n","    plt.title('Plot of Delivery Time Limits')\n","    plt.xlabel('Delivery (sorted by time limit)')\n","    plt.ylabel('Time (seconds)')\n","    plt.legend()\n","    plt.show()\n","\n","    if len(d_limits) < len(d_base_times):\n","      print(\"Differing sizes!\")\n","\n","  def plot_distance_by_step(self):\n","    grouped_data = defaultdict(list)\n","    for d in self.deliveries:\n","      grouped_data[d.step].append(full_dist_matrix[d.start_node][d.end_node])\n","\n","    labels = list(grouped_data.keys())\n","    boxplot_data = list(grouped_data.values())\n","\n","    plot = plt.boxplot(boxplot_data, labels=labels)\n","    plt.title('Plot of Delivery Distance by Step')\n","    plt.xlabel('Step (1-4)')\n","    plt.ylabel('Distance (meters)')\n","    plt.show()\n","\n","  # Function to check if two DeliveryLists are equal (have same parameters, not necessarily the same deliveries)\n","  def __eq__(self, other):\n","    if not isinstance(other, DeliveryList):\n","      return False\n","\n","    return (self.distance_based == other.distance_based and\n","            self.load == other.load and\n","            self.hours == other.hours and\n","            self.peaks == other.peaks and\n","            self.sigma == other.sigma and\n","            self.percent_max_dist == other.percent_max_dist and\n","            np.array_equal(self.distribution, other.distribution))\n","\n","  # Function to print overview of statistics\n","  def __str__(self):\n","    return f\"DeliveryList {self.id}\\n\" \\\n","           f\"Delivery distance based on '{self.distance_based}'\\n\" \\\n","           f\"Load: {self.load}\\n\" \\\n","           f\"# Deliveries: {len(self.deliveries)}\\n\" \\\n","           f\"Hours: {self.hours}\\n\" \\\n","           f\"Peaks: {self.peaks}\\n\" \\\n","           f\"Sigma: {self.sigma}\\n\" \\\n","           f\"% of Maximum Distance to Share: {self.percent_max_dist}%\\n\""]},{"cell_type":"markdown","metadata":{"id":"oGrNVIm1wuax"},"source":["###### COMPARE WITH OLD AS NECESSARY"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1746194757042,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"},"user_tz":240},"id":"ulwR7uviwunu"},"outputs":[],"source":["# mu1 = 15\n","# mu2 = 45\n","# sigma = 10\n","# load = 20\n","\n","# x = np.linspace(0, 60, 60)\n","# y1 = (1 / (sigma * np.sqrt(2*np.pi))) * np.exp(-0.5 * ((x - mu1) / sigma)**2)\n","# y2 = (1 / (sigma * np.sqrt(2*np.pi))) * np.exp(-0.5 * ((x - mu2) / sigma)**2)\n","\n","# y_combined = y1 + y2\n","# loads = [int((load*(sigma * np.sqrt(2*np.pi)))*x) for x in y_combined]\n","\n","# print(sum(loads))\n","\n","# # plt.scatter(range(len(y_combined)), y_combined)\n","# plt.scatter(range(len(loads)), loads)\n","# plt.title(\"Original\")"]},{"cell_type":"markdown","metadata":{"id":"RfpLA6Mkwywg"},"source":["### Simulation"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":341,"status":"ok","timestamp":1746194757382,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"},"user_tz":240},"id":"H5LPdwpjw4_U"},"outputs":[],"source":["class Environment:\n","\n","  def __init__(self, deliverylist:DeliveryList, num_hotspots, distance_matrix, time_matrix, Q_table, Q_orig=None):\n","    global INTERVALS\n","    global tract_super_dict\n","\n","    self.clock = 0\n","    self.time_step = 10\n","    self.radius = 1000\n","    self.is_baseline = False\n","    self.num_hotspots = num_hotspots\n","    self.distance_matrix = distance_matrix\n","    self.time_matrix = time_matrix\n","    self.shares = 0\n","    self.Q = Q_table\n","    self.total_vehicles = 0\n","    ###self.vehicle_history = list() #Never Used???\n","    self.vehicles = [0 for i in range(self.num_hotspots)]\n","    self.edge_count = [[0 for i in range(self.num_hotspots)] for j in range(self.num_hotspots)]\n","    self.deliverylist = deliverylist\n","    self.deliveries = deliverylist.deliveries\n","    self.active_deliveries = list() # deliveries that have started their journey but not reached destination\n","    self.hotspot_deliveries = list() # deliveries that have reached a hotspot during their journey\n","    self.dormant_deliveries = [delivery for delivery in self.deliveries] # deliveries yet to start their journey\n","    self.num_car_changes = 0\n","\n","    # REWARD GRAPHS\n","    self.reward_by_time = {0:[0,0]}\n","    self.reward_by_step = {0:[0,0]}\n","\n","\n","    ##For metrics\n","    self.destination_success = np.zeros((num_hotspots,), dtype=int)\n","    self.source_success = np.zeros((num_hotspots,), dtype=int)\n","    self.order_rate = np.zeros((num_hotspots,), dtype=int)\n","    self.non_local_order_rate = np.zeros((num_hotspots,), dtype=int)\n","\n","\n","    self.Q_orig = Q_orig if Q_orig else Q_table\n","    self.scale_Q()\n","\n","\n","  # scale all Q values to the range 0-1\n","  def scale_Q(self):\n","    for _, local_Q in self.Q.items():\n","      for destination in range(len(local_Q)):\n","        for source in range(len(local_Q[destination])):\n","          MIN = min(local_Q[destination][source])\n","          MAX = max(local_Q[destination][source])\n","          local_Q[destination][source] = (local_Q[destination][source] - MIN) / (MAX - MIN)\n","\n","\n","\n","  # assign deliveries to each hotspot\n","  def find_delivery_hotspot(self):\n","    self.delivery_hotspots = [list() for i in range(self.num_hotspots)]\n","\n","    for delivery in self.active_deliveries:\n","      if delivery.in_transition and delivery.next_node != delivery.end_node:\n","        self.delivery_hotspots[delivery.next_node].append(delivery)\n","      else:\n","        self.delivery_hotspots[delivery.current_node].append(delivery)\n","\n","  def run(self, sharing=True):\n","    while (self.active_deliveries or self.dormant_deliveries):\n","      self.step(sharing)\n","\n","      # if (self.clock % 1000 == 0):                                                         ###DEBUG\n","      #   print(\"\\n\", \"-\"*40)                                                               ###DEBUG\n","      #   print(\"Clock: \", self.clock)                                                      ###DEBUG\n","      #   print(\" || active_deliveries\")                                                    ###DEBUG\n","      #   print(f\"{len(self.active_deliveries)}\\tactive_deliveries.\", end=\"\\t\\t\")\n","      #   print([{\"id\": d.id, \"start\": index_to_tract[d.end_node][-4:], \"end\": index_to_tract[d.start_node][-4:]} for d in self.active_deliveries])\n","      #   print(\" || dormant_deliveries\")\n","      #   print(f\"{len(self.dormant_deliveries)}\\tdormant_deliveries.\", end=\"\\t\\t\")\n","      #   print([{\"id\": d.id, \"start\": index_to_tract[d.end_node][-4:], \"end\": index_to_tract[d.start_node][-4:]} for d in self.dormant_deliveries])\n","      #   print(\"\\n\\n\")\n","      # if(self.clock >= 50000):\n","      #   break\n","\n","  def add_reward_time(self):\n","    pass\n","\n","\n","  def step(self,sharing=True):\n","\n","    # add new deliveries\n","    self.add_deliveries()\n","\n","    # increment global time\n","    self.clock += self.time_step\n","\n","    # assign deliveries to hotspots\n","    self.find_delivery_hotspot()\n","\n","    # set next nodes\n","    self.set_next_nodes(sharing)\n","\n","    # empty the hotspot_deliveries list to prepare for next step\n","    self.hotspot_deliveries = list()\n","\n","    to_remove = list()\n","    vehicle_debt = [0 for i in range(self.num_hotspots)]\n","\n","    for delivery in self.active_deliveries:\n","\n","      # move the delivery forward if its not waiting for any other delivery (4 cases where this happens)\n","      if delivery.in_transition or delivery.sharing_with is None or delivery.sharing_with.current_node==delivery.current_node or delivery.current_node != delivery.sharing_node:\n","        delivery.time_till_next_node -= self.time_step\n","        if not delivery.in_transition and ((delivery.is_primary) or (delivery.sharing_with is not None and delivery.current_node != delivery.sharing_with.current_node)):\n","          vehicle_debt[delivery.current_node] -= 1\n","        delivery.in_transition = True\n","\n","        if delivery.time_till_next_node <= 0:\n","          delivery.in_transition = False\n","          if delivery.is_primary or (delivery.sharing_with is not None and delivery.current_node != delivery.sharing_with.current_node):\n","            self.vehicles[delivery.next_node] += 1\n","          delivery.current_node = delivery.next_node\n","          self.update_step(delivery)  # Update step to make sure it is correct\n","\n","          if delivery.current_node == delivery.end_node:\n","            if delivery.sharing_with is not None:\n","              delivery.sharing_with.is_primary = True\n","              delivery.sharing_with.sharing_with = None\n","              delivery.sharing_with = None\n","            delivery.end_time = self.clock + delivery.time_till_next_node\n","            delivery.completed = True\n","            to_remove.append(delivery)\n","\n","          delivery.time_till_next_node = 0\n","\n","\n","      # check for deliveries that have reached a hotspot\n","      if delivery.in_transition == False and delivery.completed == False:\n","        self.hotspot_deliveries.append(delivery)\n","\n","    for delivery in to_remove:\n","      # if delivery.did_share:\n","      # print(\"/\\\\\"*20, \"\\ndelivery arrived!\") ###DEBUG\n","      # if delivery.did_share:  # Remove when done\n","      #   ###DEBUG\n","      #   print(f\"\"\"Delivery {delivery.id}\n","      #   Start Hotspot: \\t {index_to_tract[delivery.start_node][-4:]}\n","      #   End Hotspot: \\t {index_to_tract[delivery.end_node][-4:]}\n","      #   Same Hotspot: \\t {strings_in_same_sublist(index_to_tract[delivery.start_node], index_to_tract[delivery.end_node])}\n","      #   Path: \\t \\t {[index_to_tract[n][-4:] for n in delivery.path]}\n","      #   Did share: \\t {delivery.did_share}\n","      #   Shared with: \\t {delivery.shared_with_final.id}\n","      #   Started sharing: \\t {index_to_tract[delivery.shared_with_when]}\"\"\"\n","      #   )\n","      #   graph_path_delivery(delivery=delivery, show_geoids=False)  ###DEBUG\n","\n","      self.active_deliveries.remove(delivery)\n","\n","    if self.is_baseline:\n","      for i in range(self.num_hotspots):\n","        minimum = self.baseline_data[index_to_tract[i]]['min_time']\n","        maximum = self.baseline_data[index_to_tract[i]]['max_time']\n","        prob = [random.randint(minimum, maximum) for x in range(self.vehicles[i])]\n","\n","        count = 0\n","        limit = 120 if len(self.deliveries)<1200 else 150\n","        for x in prob:\n","          if x<=limit: count+=1\n","\n","        if (abs(vehicle_debt[i]) <= count):\n","          self.vehicles[i] += vehicle_debt[i]\n","        else:\n","          self.vehicles[i] = 0\n","          self.total_vehicles += (abs(vehicle_debt[i])-count)\n","\n","    else:\n","      for i in range(self.num_hotspots):\n","        self.vehicles[i] += vehicle_debt[i]\n","        if self.vehicles[i] < 0:\n","          self.total_vehicles += -(self.vehicles[i])\n","          self.vehicles[i] = 0\n","\n","  # adds new deliveries according to start time of deliveries : FIFO order\n","  def add_deliveries(self):\n","    for delivery in reversed(self.dormant_deliveries):\n","      if delivery.start_time <= self.clock:\n","        self.active_deliveries.append(delivery)\n","        self.hotspot_deliveries.append(delivery)\n","        self.dormant_deliveries.remove(delivery)\n","\n","  # sets the next nodes of deliveries\n","  def set_next_nodes(self, sharing):\n","\n","    if sharing:\n","\n","      for delivery in self.hotspot_deliveries:\n","\n","        # set for sharing\n","        if delivery.sharing_with is not None:\n","\n","          # sharing has started\n","          if delivery.current_node == delivery.sharing_with.current_node:\n","            common_node = self.common_next(delivery, delivery.sharing_with)[0]\n","\n","            # further sharing possible\n","            if common_node is not None:\n","              delivery.next_node = common_node\n","              delivery.path.append(common_node)\n","              self.update_order_rate(common_node, delivery)\n","              if delivery.is_primary:\n","                delivery.distance_traveled += self.distance_matrix[delivery.current_node][delivery.next_node]\n","                # self.edge_count[delivery.current_node][delivery.next_node] += 1\n","              delivery.time_till_next_node = self.time_matrix[delivery.current_node][delivery.next_node]\n","              delivery.sharing_with.time_till_next_node = delivery.time_till_next_node\n","\n","            # no further sharing possible\n","            else:\n","              delivery.sharing_with.is_primary = True\n","              delivery.is_primary = True\n","              delivery.sharing_with.sharing_with = None\n","              delivery.sharing_with = None\n","\n","\n","          # sharing has not started and arriving at non-shared node\n","          elif delivery.current_node != delivery.sharing_node:\n","            delivery.next_node = delivery.sharing_node\n","            delivery.path.append(delivery.next_node)\n","            self.update_order_rate(delivery.next_node, delivery)\n","            # Add distance and time traveled to delivery total\n","            delivery.distance_traveled += self.distance_matrix[delivery.current_node][delivery.next_node]\n","            delivery.time_till_next_node = self.time_matrix[delivery.current_node][delivery.next_node]\n","\n","\n","      share_deliveries = list()\n","\n","      for delivery in self.hotspot_deliveries:\n","\n","        # if not sharing then add sharing pairs\n","        if delivery.sharing_with is None:\n","          share_deliveries += self.share_with(delivery)\n","\n","      share_deliveries.sort()\n","\n","      ## REQUEST HANDLER [start]\n","\n","      for pair in share_deliveries:\n","        del1 = pair[1]\n","        del2 = pair[2]\n","        common_node = pair[3]\n","\n","        n1 = del1.next_node if del1.in_transition else del1.current_node\n","        n2 = del2.next_node if del2.in_transition else del2.current_node\n","\n","        clause1 = del1.sharing_with is None and del2.sharing_with is None\n","        clause2 = del1.end_node != n2 and del2.end_node != n1\n","\n","        if clause1 and clause2:\n","          del1.sharing_with = del2\n","          del2.sharing_with = del1\n","\n","          del1.num_car_changes += 1\n","          del2.num_car_changes += 1\n","          self.shares += 1\n","\n","\n","          # For debugging with deliveries\n","          del1.did_share = True\n","          del2.did_share = True\n","\n","          del1.shared_with_final = del2\n","          del2.shared_with_final = del1\n","\n","          del1.shared_with_when = n1\n","          del2.shared_with_when = n2\n","          ##############################\n","\n","          del1.sharing_node = common_node\n","          del2.sharing_node = common_node\n","\n","          del1.is_primary = True\n","          del2.is_primary = False\n","\n","          if (not del1.in_transition):\n","            del1.next_node = common_node\n","            # self.edge_count[del1.current_node][del1.next_node] += 1\n","            if(del1.is_primary):\n","              del1.distance_traveled += self.distance_matrix[del1.current_node][del1.next_node]\n","            del1.path.append(common_node)\n","            self.update_order_rate(common_node, del1)\n","            del1.time_till_next_node = self.time_matrix[del1.current_node][del1.next_node]\n","\n","          if (not del2.in_transition):\n","            del2.next_node = common_node\n","            # self.edge_count[del2.current_node][del2.next_node] += 1\n","            if(del2.is_primary):\n","              del2.distance_traveled += self.distance_matrix[del2.current_node][del2.next_node]\n","            del2.path.append(common_node)\n","            self.update_order_rate(common_node, del2)\n","            del2.time_till_next_node = self.time_matrix[del2.current_node][del2.next_node]\n","\n","      ## REQUEST HANDLER [end]\n","\n","    # set next nodes for those deliveries that cannot share\n","    for delivery in self.hotspot_deliveries:\n","      if delivery.sharing_with is None:\n","        delivery.next_node = self.next_node(delivery)\n","        delivery.is_primary = True\n","        # self.edge_count[delivery.current_node][delivery.next_node] += 1\n","        delivery.distance_traveled += self.distance_matrix[delivery.current_node][delivery.next_node]\n","        delivery.path.append(delivery.next_node)\n","        self.update_order_rate(delivery.next_node, delivery)\n","        delivery.time_till_next_node = self.time_matrix[delivery.current_node][delivery.next_node]\n","\n","\n","  # return list of deliveries to share path with as `[(Q_VALUE, DELIVERY, DELIVERY, COMMON NODE)]`\n","  def update_order_rate(self, node, delivery):\n","    self.order_rate[node] += 1\n","    if (delivery.start_node != node and delivery.start_node != node):\n","      self.non_local_order_rate[node] += 1\n","\n","  def share_with(self, del1):\n","\n","    pairs = list()\n","\n","    # May need to change super-spot group selection to include nearby super-spots\n","    del_group = [ del1.current_node ] if del1.step == 2 else tract_group_lists[tract_super_dict[del1.current_node]]  # Change [ del1.current_node ] to tract_super_dict[del1.current_node] if you want to include super-spot network\n","    # del_group = [del1.current_node]\n","\n","\n","\n","    for hotspot in del_group:\n","      for del2 in self.delivery_hotspots[hotspot]:\n","        if (del1 != del2 and del2.sharing_with is None and del2.next_node != del2.end_node):\n","          common = self.common_next(del1, del2)\n","          if common[0] is not None:\n","            pairs.append((common[1], del1, del2, common[0]))\n","\n","    return pairs\n","\n","\n","  def add_reward_list(self, delivery, action_list):\n","    min_Q = np.min(action_list)\n","    curr_step = len(delivery.path)\n","\n","    if curr_step not in self.reward_by_step.keys():\n","      self.reward_by_step[curr_step] = [0,0]\n","    self.reward_by_step[curr_step][0] -= min_Q\n","    self.reward_by_step[curr_step][1] += 1\n","\n","    if self.clock not in self.reward_by_time.keys():\n","      self.reward_by_time[self.clock] = [0,0]\n","    self.reward_by_time[self.clock][0] -= min_Q\n","    self.reward_by_time[self.clock][1] += 1\n","\n","\n","  # return best next node of single delivery as `node`\n","  def next_node(self, delivery):\n","    if delivery.step == 1:  # Get to super-spot of current group\n","      local_Q = self.Q[tract_super_dict[delivery.current_node]]  # Q table of local group\n","      dest_node = tract_super_dict[delivery.current_node]  # Sets destination node to super-spot of local group\n","\n","      # List if actions in local Q table given curr location and destination\n","      action_list = local_Q[index_to_Q[ dest_node ]][index_to_Q[ delivery.current_node ]]\n","      self.add_reward_list(\n","          delivery,\n","          self.Q_orig[tract_super_dict[delivery.current_node]][index_to_Q[ dest_node ]][index_to_Q[ delivery.current_node ]]\n","      )\n","      return Q_to_index[tract_super_dict[delivery.current_node]][np.argmin(action_list)]  # Get minimum Q value, then convert to global\n","\n","    elif delivery.step == 2:  # In super-spot layer, get to next super-spot\n","      local_Q = self.Q[-1]  # Super-spot Q table\n","      dest_node = tract_super_dict[delivery.end_node]  # Super-spot of destination node as temp dest\n","\n","      # List if actions in super-spot table given curr location and final destination\n","      action_list = local_Q[index_to_Q_super[ dest_node ]][index_to_Q_super[ delivery.current_node ]]\n","      self.add_reward_list(\n","          delivery,\n","          self.Q_orig[-1][index_to_Q_super[ dest_node ]][index_to_Q_super[ delivery.current_node ]]\n","      )\n","      return Q_super_to_index[np.argmin(action_list)]\n","\n","\n","    elif delivery.step == 3:  # In final group, get pathing to final destination\n","      local_Q = self.Q[tract_super_dict[delivery.end_node]]\n","      dest_node = delivery.end_node\n","\n","      action_list = local_Q[index_to_Q[ dest_node ]][index_to_Q[ delivery.current_node ]]\n","      self.add_reward_list(\n","          delivery,\n","          self.Q_orig[tract_super_dict[delivery.end_node]][index_to_Q[ dest_node ]][index_to_Q[ delivery.current_node ]]\n","      )\n","      return Q_to_index[tract_super_dict[delivery.current_node]][np.argmin(action_list)]\n","\n","    elif delivery.step == 4:  # Hotspots bordering but in different groups, travel directly to destination\n","      return delivery.end_node\n","\n","  # Updates what step the delivery is at\n","  def update_step(self, delivery):\n","    if delivery.step == 4:\n","      delivery.step = 4\n","\n","    elif tract_super_dict[delivery.current_node] != tract_super_dict[delivery.end_node] and delivery.current_node not in list(index_to_Q_super.keys()):  # current node super-table != dest node super-table and not at a super-spot\n","      delivery.step = 1\n","\n","    # tract_super_dict[delivery.current_node] == delivery.current_node is TRUE\n","    elif tract_super_dict[delivery.current_node] != tract_super_dict[delivery.end_node] and delivery.current_node in list(index_to_Q_super.keys()):  # current node super-table != dest node super-table and is at a super-spot\n","      delivery.step = 2\n","\n","    elif tract_super_dict[delivery.current_node] == tract_super_dict[delivery.end_node]:  # current node super-table == dest node super-table\n","      delivery.step = 3\n","\n","\n","  def common_next(self, del1, del2):\n","\n","    node1 = del1.next_node if del1.in_transition else del1.current_node\n","    node2 = del2.next_node if del2.in_transition else del2.current_node\n","\n","    # Make sure steps are equal\n","    if del1.step != del2.step:\n","      return (None, None)\n","\n","\n","    ###we could check here for if the share could be bad\n","\n","    common_step = del1.step\n","    if common_step == 1:\n","      local_Q = self.Q[tract_super_dict[del1.current_node]]\n","      super_spot = tract_super_dict[node1]\n","      Q_value = local_Q[index_to_Q[super_spot]][index_to_Q[del1.current_node]][index_to_Q[super_spot]] + local_Q[index_to_Q[super_spot]][index_to_Q[del2.current_node]][index_to_Q[super_spot]]\n","\n","      self.add_reward_list(\n","          del1,\n","          self.Q_orig[tract_super_dict[del1.current_node]][index_to_Q[super_spot]][index_to_Q[del1.current_node]][index_to_Q[super_spot]]\n","      )\n","\n","      self.add_reward_list(\n","          del2,\n","          self.Q_orig[tract_super_dict[del1.current_node]][index_to_Q[super_spot]][index_to_Q[del2.current_node]][index_to_Q[super_spot]]\n","      )\n","\n","      return (super_spot, Q_value)\n","\n","    elif common_step == 2:\n","      local_Q = self.Q[-1]\n","\n","      actions_del1 = local_Q[index_to_Q_super[tract_super_dict[del1.end_node]]][index_to_Q_super[node1]]\n","      actions_del2 = local_Q[index_to_Q_super[tract_super_dict[del2.end_node]]][index_to_Q_super[node2]]\n","\n","\n","      actions = actions_del1 + actions_del2\n","      actions_indexes = list(range(len(actions)))\n","\n","      # Remove all actions where sharing does not benefit both deliveries\n","      for action in range(len(actions)):\n","        if self.distance_matrix[node1, tract_super_dict[del1.end_node]] <= self.distance_matrix[Q_super_to_index[action], tract_super_dict[del1.end_node]] or self.distance_matrix[node2, tract_super_dict[del2.end_node]] <= self.distance_matrix[Q_super_to_index[action], tract_super_dict[del2.end_node]]:\n","          actions_indexes.remove(action)\n","\n","      min_Q = 10000000\n","      best_action = None\n","      for idx, Q_value in enumerate(actions):\n","        if idx in actions_indexes:\n","          if Q_value < min_Q:\n","            min_Q = Q_value\n","            best_action = idx\n","\n","      if best_action is not None:\n","        self.add_reward_list(\n","            del1,\n","            np.array(self.Q_orig[-1][index_to_Q_super[tract_super_dict[del1.end_node]]][index_to_Q_super[node1]])[actions_indexes]\n","        )\n","\n","        self.add_reward_list(\n","            del2,\n","            np.array(self.Q_orig[-1][index_to_Q_super[tract_super_dict[del2.end_node]]][index_to_Q_super[node2]])[actions_indexes]\n","        )\n","\n","      return (Q_super_to_index[best_action], min_Q) if best_action is not None else (None, None)\n","\n","    elif common_step == 3:\n","      local_Q = self.Q[tract_super_dict[del1.end_node]]\n","\n","      actions_del1 = local_Q[index_to_Q[del1.end_node]][index_to_Q[node1]]\n","      actions_del2 = local_Q[index_to_Q[del2.end_node]][index_to_Q[node2]]\n","      actions = actions_del1 + actions_del2\n","      actions_indexes = list(range(len(actions)))  # List of possible actions\n","\n","      # get a list of actions that have already been taken so that they can be removed from consideration\n","      for action in tract_group_lists[tract_super_dict[del1.end_node]]:\n","        # If actions has already been traversed OR action is not beneficial to both deliveries...\n","        if action in del1.path or (self.distance_matrix[node1, del1.end_node] <= self.distance_matrix[action, del1.end_node] or self.distance_matrix[node2, del2.end_node] <= self.distance_matrix[action, del2.end_node]):\n","          actions_indexes.remove(index_to_Q[action])\n","\n","      # If no actions return none\n","      if len(actions_indexes) == 0:\n","        return (None, None)\n","\n","      min_Q = 10000000\n","      best_action = None\n","      for idx, Q_value in enumerate(actions):\n","        if idx in actions_indexes:\n","          if Q_value < min_Q:\n","            min_Q = Q_value\n","            best_action = idx\n","\n","      if best_action is not None:\n","        self.add_reward_list(\n","            del1,\n","            np.array(self.Q_orig[tract_super_dict[del1.end_node]][index_to_Q[del1.end_node]][index_to_Q[node1]])[actions_indexes]\n","        )\n","\n","        self.add_reward_list(\n","            del2,\n","            np.array(self.Q_orig[tract_super_dict[del1.end_node]][index_to_Q[del2.end_node]][index_to_Q[node2]])[actions_indexes]\n","        )\n","\n","      return (Q_to_index[tract_super_dict[del1.end_node]][best_action], min_Q) if best_action is not None else (None, None)\n","\n","    else:  # This will prevent step 4 from sharing.\n","      return (None, None)\n","\n","\n","  def reset(self):\n","    self.deliverylist.reset_deliveries()\n","    self.__init__(deliverylist=self.deliverylist, num_hotspots=self.num_hotspots, distance_matrix=self.distance_matrix, time_matrix=self.time_matrix, Q_table=self.Q)\n","\n","\n","\n","\n","  def calculate_vehicle_change_times(self, fixed=True, factorMin=15, factorMax=30): #fixed means it will alwyas use the minimum factor while if it is not fixed it will randomly choose an integer value between factorMin and factorMax inclusive\n","    vehicle_change_times = dict()\n","\n","    for delivery in self.deliveries:\n","      if(fixed):\n","        vehicle_change_times[delivery] = delivery.num_car_changes * factorMin\n","      else:\n","        tot = 0\n","        for i in range(delivery.num_car_changes):\n","          tot += random.randint(factorMin, factorMax)\n","\n","        vehicle_change_times[delivery] = tot\n","\n","    return vehicle_change_times\n","\n","\n","  def check_delivery_timelimit_success(self, delivery, time_val):\n","    # IMPORTANT: I am defining these manually assuming they will not change\n","    #  and that hours = 1.\n","    total_seconds = 3600*self.deliverylist.hours\n","    sd = self.deliverylist.sigma/60.0  # convert standard deviation in minutes to hours\n","\n","    # This determines which peak the delivery is closest to. Then it gets the time difference between that\n","    #  peak and the delivery starting time.\n","    peak_diff = min(abs(total_seconds * peak - delivery.start_time) for peak in self.deliverylist.peaks)\n","\n","    # Now we determine how many std. deviations away from that peak it is closer to.\n","    num_sd_away = peak_diff / (total_seconds*sd)\n","\n","    # The closer to the peak, the more time we want to give a delivery.\n","    # In our formulation for time limit L, we will use the equation L = T * max{1, (2 - S)}, where T is the original delivery\n","    #   time limit and S how many standard deviations away the delivery start time is from its closest peak time. So when a\n","    #   delivery is the max possible standard deviations away from a peak, L = T. Otherwise, it will be boosted as it approaches\n","    #   peak hours.\n","\n","    time_limit = delivery.time_limit * max(1, (2 - num_sd_away))\n","\n","    return time_val < time_limit\n","\n","  def results(self):\n","    with open(data_dir + \"/avg_hotspot_data.json\") as f:\n","      hotspot = json.load(f)\n","\n","    distances = list()\n","    distances_tagged = list()\n","    times = list()\n","    times_tagged = list()\n","    wait = 0\n","    hops = 0\n","    vehicle_change_times = self.calculate_vehicle_change_times(self)\n","\n","    for delivery in self.deliveries:\n","      t = delivery.end_time - delivery.start_time + hotspot[index_to_tract[delivery.end_node]]['time'] + hotspot[index_to_tract[delivery.start_node]]['time'] + vehicle_change_times[delivery]\n","      if self.check_delivery_timelimit_success(delivery, t):\n","        delivery.successful = True\n","        self.destination_success[delivery.start_node] += 1\n","        self.source_success[delivery.end_node] += 1\n","\n","    for delivery in self.deliveries:\n","      t = delivery.end_time - delivery.start_time + hotspot[index_to_tract[delivery.end_node]]['time'] + hotspot[index_to_tract[delivery.start_node]]['time'] + vehicle_change_times[delivery]\n","      d = delivery.distance_traveled + hotspot[index_to_tract[delivery.start_node]]['distance'] + hotspot[index_to_tract[delivery.end_node]]['distance']\n","\n","      distances.append( d )\n","      distances_tagged.append( (d, delivery.did_share, delivery.successful) )\n","      times.append( t )\n","      times_tagged.append( (t, delivery.did_share, delivery.successful) )\n","\n","      if delivery.successful:\n","\n","        hops += len(delivery.path) - 1\n","\n","        path_time = 0\n","        for i in range(len(delivery.path)-1):\n","          path_time += self.time_matrix[delivery.path[i]][delivery.path[i+1]]\n","\n","        wait += (delivery.end_time - delivery.start_time) + vehicle_change_times[delivery] - path_time\n","\n","    successful_deliveries = [delivery for delivery in self.deliveries if delivery.successful]\n","    successful_delivery_count = len(successful_deliveries)\n","    distance = sum(distances)\n","\n","    data = dict()\n","    data['shares'] = self.shares\n","    data['success_rate'] = successful_delivery_count / len(self.deliveries)\n","    data['success_rate_grouped'] = dict.fromkeys(INTERVALS, 0)\n","\n","    for interval in INTERVALS:\n","      interval_delivs = [d for d in self.deliveries if d.time_limit == interval]\n","      interval_successfuls = [d for d in interval_delivs if d.successful]\n","      data['success_rate_grouped'][interval] = len(interval_successfuls) / max(1, len(interval_delivs))\n","\n","    data['description'] = \"results\"\n","    data['sharing'] = True\n","    data['distances'] = distances\n","    data['distances_tagged'] = distances_tagged\n","    data['times'] = times\n","    data['times_tagged'] = times_tagged\n","    data['wait'] = wait/len(successful_deliveries)\n","    data['hops'] = (hops+2*len(successful_deliveries))/len(successful_deliveries)\n","    data['hops_all'] = (hops+2*len(self.deliveries)) / float(len(self.deliveries))  # I think this is correct?\n","    data['CDV'] = int(self.total_vehicles)\n","    data['PDV'] = int(self.calculate_PDV())\n","    data['destination_success'] = self.destination_success\n","    data['source_success'] = self.source_success\n","    data['order_rate'] = self.order_rate\n","    data['non_local_order_rate'] = self.non_local_order_rate\n","    data['reward_by_time'] = self.reward_by_time\n","    data['reward_by_step'] = self.reward_by_step\n","\n","    return data\n","\n","  # No pathsharing, uses hotspots, no super-spots\n","  def baseline1(self):\n","    self.reset()\n","\n","    with open(data_dir + \"/avg_hotspot_data.json\") as f:\n","      hotspot = json.load(f)\n","\n","\n","    distances = list()\n","    distances_tagged = list()\n","    times = list()\n","    times_tagged = list()\n","\n","    delivery_success_grouped = {interval: [0, 0] for interval in INTERVALS}\n","\n","    # Use distance/time matrices that are accurate for whole city.\n","    successful_delivery_count = 0\n","    for delivery in self.deliveries:\n","\n","      interval_greater = np.array(INTERVALS) >= delivery.time_limit\n","      grouped_index = INTERVALS[np.argmax(interval_greater)]\n","\n","      delivery_success_grouped[grouped_index][1] += 1\n","\n","      distance_val = self.distance_matrix[delivery.start_node][delivery.end_node] + hotspot[index_to_tract[delivery.start_node]][\"distance\"] + hotspot[index_to_tract[delivery.end_node]][\"distance\"]\n","      time_val = self.time_matrix[delivery.start_node][delivery.end_node] + hotspot[index_to_tract[delivery.start_node]][\"time\"] + hotspot[index_to_tract[delivery.end_node]][\"time\"]\n","\n","      delivery_timelim_success = bool(self.check_delivery_timelimit_success(delivery, time_val))\n","\n","      if delivery_timelim_success:\n","        successful_delivery_count += 1\n","        delivery_success_grouped[grouped_index][0] += 1\n","\n","      distances.append(distance_val)\n","      times.append(time_val)\n","\n","      distances_tagged.append( (distance_val, False, delivery_timelim_success) )\n","      times_tagged.append( (time_val, False, delivery_timelim_success) )\n","\n","\n","    self.reset()\n","    self.run(False)\n","\n","    data = dict()\n","    data['shares'] = 0\n","    data['success_rate'] = successful_delivery_count / len(self.deliveries)\n","    data['success_rate_grouped'] = {k: v[0] / max(1, v[1]) for k, v in delivery_success_grouped.items()}\n","    data['description'] = \"uses hotspots, does not use super-spots\"\n","    data['sharing'] = False\n","    data['distances'] = distances\n","    data['distances_tagged'] = distances_tagged\n","    data['times'] = times\n","    data['times_tagged'] = times_tagged\n","    data['wait'] = 0\n","    data['hops'] = 3\n","    data['hops_all'] = 3\n","    data['CDV'] = int(self.total_vehicles)\n","    data['PDV'] = int(self.calculate_PDV())\n","    return data\n","\n","  def baseline1_fast(self):\n","    with open(data_dir + \"/avg_hotspot_data.json\") as f:\n","      hotspot = json.load(f)\n","\n","\n","    distances = list()\n","    distances_all = list()\n","    times = list()\n","    times_all = list()\n","\n","    # Use distance/time matrices that are accurate for whole city.\n","    delivery_number = 0\n","    successful_delivery_count = 0\n","    for delivery in self.deliveries:\n","      delivery_number += 1\n","\n","      distance_val = self.distance_matrix[delivery.start_node][delivery.end_node] + hotspot[index_to_tract[delivery.start_node]][\"distance\"] + hotspot[index_to_tract[delivery.end_node]][\"distance\"]\n","      time_val = self.time_matrix[delivery.start_node][delivery.end_node] + hotspot[index_to_tract[delivery.start_node]][\"time\"] + hotspot[index_to_tract[delivery.end_node]][\"time\"]\n","\n","      if self.check_delivery_timelimit_success(delivery, time_val):\n","        successful_delivery_count += 1\n","\n","        distances.append(distance_val)\n","        times.append(time_val)\n","\n","      distances_all.append(distance_val)\n","      times_all.append(time_val)\n","\n","    data = dict()\n","    data['shares'] = 0\n","    data['success_rate'] = successful_delivery_count / delivery_number\n","    data['description'] = \"uses hotspots, does not use super-spots\"\n","    data['sharing'] = False\n","    data['distances'] = distances\n","    data['distances_all'] = distances_all\n","    data['total_distance_all'] = sum(distances_all)/1000  # Total distance for all including failed in km\n","    data['total_distance'] = sum(distances)/1000  # Total distance in km\n","    data['mean_distance'] = (sum(distances)/1000)/successful_delivery_count  # Mean distance in km\n","    data['median_distance'] = np.median(distances)/1000  # Median distance in km\n","    data['times'] = times\n","    data['mean_time'] = round( sum(times)/successful_delivery_count, 2)\n","    data['median_time'] = np.median(times)\n","    data['wait'] = 0\n","    data['hops'] = 3\n","    return data\n","\n","\n","  # No pathsharing, uses hotspots, uses super-spots\n","  def baseline2(self):\n","    self.reset()\n","\n","    with open(data_dir + \"/avg_hotspot_data.json\") as f:\n","      hotspot = json.load(f)\n","\n","    distances = list()\n","    distances_tagged = list()\n","    times = list()\n","    times_tagged = list()\n","\n","    delivery_success_grouped = {interval: [0, 0] for interval in INTERVALS}\n","\n","    total_hops = 0\n","    total_hops_all = 0  # Regardless of success\n","    successful_delivery_count = 0\n","    for delivery in self.deliveries:\n","      delivery_success_grouped[delivery.time_limit][1] += 1\n","\n","      # Distances and times within census tract added\n","      distance_val = hotspot[index_to_tract[delivery.start_node]][\"distance\"] + hotspot[index_to_tract[delivery.end_node]][\"distance\"]  # Set to average hotspot values for start and end\n","      time_val = hotspot[index_to_tract[delivery.start_node]][\"time\"] + hotspot[index_to_tract[delivery.end_node]][\"time\"]  # Same here\n","\n","      # If in same group, just get direct path distance/time\n","      if tract_super_dict[delivery.start_node] == tract_super_dict[delivery.end_node] or delivery.step == 4:\n","        distance_val += self.distance_matrix[delivery.start_node][delivery.end_node]\n","        time_val += self.time_matrix[delivery.start_node][delivery.end_node]\n","\n","        hops_to_add = 3\n","\n","      # Otherwise get distance/time from steps\n","      else:\n","        distance_val += self.distance_matrix[delivery.start_node][tract_super_dict[delivery.start_node]]\n","        time_val += self.time_matrix[delivery.start_node][tract_super_dict[delivery.start_node]]\n","\n","        distance_val += self.distance_matrix[tract_super_dict[delivery.start_node]][tract_super_dict[delivery.end_node]]\n","        time_val += self.time_matrix[tract_super_dict[delivery.start_node]][tract_super_dict[delivery.end_node]]\n","\n","        distance_val += self.distance_matrix[tract_super_dict[delivery.end_node]][delivery.end_node]\n","        time_val += self.time_matrix[tract_super_dict[delivery.end_node]][delivery.end_node]\n","\n","        # Compute hops\n","        hops_to_add = 5\n","        if delivery.start_node == tract_super_dict[delivery.start_node]:\n","          hops_to_add -= 1\n","        if delivery.end_node == tract_super_dict[delivery.end_node]:\n","          hops_to_add -= 1\n","\n","      delivery_timelim_success = bool(self.check_delivery_timelimit_success(delivery, time_val))\n","      if delivery_timelim_success:\n","        delivery_success_grouped[delivery.time_limit][0] += 1\n","        total_hops += hops_to_add\n","        successful_delivery_count += 1\n","\n","      distances.append(distance_val)\n","      times.append(time_val)\n","\n","      distances_tagged.append( (distance_val, False, delivery_timelim_success) )\n","      times_tagged.append( (time_val, False, delivery_timelim_success) )\n","\n","      total_hops_all += hops_to_add\n","\n","\n","\n","    self.reset()\n","    self.run(False)\n","\n","    data = dict()\n","    data['shares'] = 0\n","    data['success_rate'] = successful_delivery_count / len(self.deliveries)\n","    data['success_rate_grouped'] = {k: v[0] / max(1, v[1]) for k, v in delivery_success_grouped.items()}\n","    data['description'] = \"uses hotspots, uses super-spots\"\n","    data['sharing'] = False\n","    data['distances'] = distances\n","    data['distances_tagged'] = distances_tagged\n","    data['times'] = times\n","    data['times_tagged'] = times_tagged\n","    data['wait'] = 0\n","    data['hops'] = float(total_hops) / float(successful_delivery_count)\n","    data['hops_all'] = float(total_hops_all) / float(len(self.deliveries))\n","    data['CDV'] = int(self.total_vehicles)\n","    data['PDV'] = int(self.calculate_PDV())\n","    return data\n","\n","\n","  def calculate_PDV(self):\n","\n","    with open(data_dir + \"/avg_hotspot_data.json\") as f:\n","      data = json.load(f)\n","\n","    PDV_count = 0\n","    tolerance = 2*self.time_step\n","\n","    for hotspot in range(self.num_hotspots):\n","      events = []\n","      for delivery in self.deliveries:\n","        if (delivery.start_node == hotspot):\n","          events.append((delivery.start_time - data[index_to_tract[hotspot]][\"time\"] + tolerance, 1))\n","          events.append((delivery.start_time - tolerance, -1))\n","        elif (delivery.end_node == hotspot):\n","          events.append((delivery.end_time + tolerance, 1))\n","          events.append((delivery.end_time + data[index_to_tract[hotspot]][\"time\"] - tolerance, -1))\n","\n","      # Sort the events list based on time, considering both start and end times\n","      events.sort()\n","\n","      # Iterate through the events list to find the maximum number of active deliveries\n","      max_active_deliveries = 0\n","      active_deliveries = 0\n","      for _, delta in events:\n","        active_deliveries += delta\n","        max_active_deliveries = max(max_active_deliveries, active_deliveries)\n","\n","      PDV_count += max_active_deliveries\n","\n","    return PDV_count"]},{"cell_type":"markdown","metadata":{"id":"f9XTbZx50UEQ"},"source":["## Simulate"]},{"cell_type":"markdown","metadata":{"id":"3-1zTC4-003i"},"source":["First, define the parameters of the delivery set you are going to be using in this simulation."]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1746194758168,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"},"user_tz":240},"id":"71JML8vD00J1"},"outputs":[],"source":["distance_based = \"random\"\n","load = 300\n","percent_max_dist = 100\n","hours = 1  # By default\n","peaks = [0.25, 0.75]  # By default\n","sigma = 10  # By default\n","check_OMSD = False\n","single_run = True"]},{"cell_type":"markdown","metadata":{"id":"-5OMr08y0aiP"},"source":["### Determine Optimal Minimum Sharing Distance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6L-9NKgygU-"},"outputs":[],"source":["if(check_OMSD):\n","  deliveries_graphing_dir = deliveries_dir + \"/Graphing\"\n","  try:\n","    os.mkdir(deliveries_graphing_dir)\n","  except:\n","    print(deliveries_graphing_dir + \" Already Exists\")\n","\n","  percs_to_check = range(101)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7qToqtfi0XZZ"},"outputs":[],"source":["if(check_OMSD):\n","  res_dist = list()\n","  base1_dist = list()\n","  diff = list()\n","\n","\n","  ## UNCOMMENT THE BELOW IF YOU HAVEN'T GENERATED ALL THE GRAPH DELIVERY SETS YET FOR ANY RATIO IN THE CITY!\n","  # deliv_list = DeliveryList(distance_based=distance_based, load=load, hours=hours, peaks=peaks, sigma=sigma, percent_max_dist=percent_max_dist)\n","  ###########################################\n","\n","  deliv_list = DeliveryList.load_deliveries(\n","    DeliveryList.gen_deliveries_id(distance_based=distance_based, load=load,\n","      hours=hours, peaks=peaks, sigma=sigma, percent_max_dist=percent_max_dist)\n","  )\n","\n","  if \"sim_results\" in os.listdir(deliveries_graphing_dir):\n","    with open (deliveries_graphing_dir + f\"/sim_results\", 'rb') as fp:\n","      res_dist = pickle.load(fp)\n","\n","    with open (deliveries_graphing_dir + f\"/baseline_results\", 'rb') as fp:\n","      base1_dist = pickle.load(fp)\n","\n","    percs_to_check = range(len(res_dist), 101)\n","\n","  for i in tqdm(percs_to_check):\n","\n","    deliveries_id = DeliveryList.gen_deliveries_id(distance_based=distance_based,\n","        load=load, hours=hours, peaks=peaks, sigma=sigma, percent_max_dist=i)\n","\n","    if deliveries_id not in os.listdir(deliveries_graphing_dir):\n","      new_deliv_list = deliv_list.copy()\n","      new_deliv_list.reset_deliveries(i)\n","\n","      DeliveryList.save_deliveries(new_deliv_list, graph=True)\n","\n","    else:\n","      new_deliv_list = DeliveryList.load_deliveries(deliveries_id, graph=True)\n","\n","\n","    env = Environment(new_deliv_list, num_hotspots, full_dist_matrix, full_time_matrix, Q_tables)\n","    env.run()\n","\n","    # Get results\n","    results = env.results()\n","    res_dist.append(sum(results['distances'])/1000)\n","\n","    # Get baseline data\n","    if base1_dist == []:\n","      baseline1 = env.baseline1_fast()\n","      base1_dist.append(baseline1['total_distance_all'])\n","    else:\n","      base1_dist.append(base1_dist[-1])\n","\n","    with open(deliveries_graphing_dir + f\"/sim_results\", 'wb') as fp:\n","      pickle.dump(res_dist, fp)\n","    with open(deliveries_graphing_dir + f\"/baseline_results\", 'wb') as fp:\n","      pickle.dump(base1_dist, fp)\n","\n","  print()\n","\n","  # Get smallest percentage\n","  min_perc = percs_to_check[np.argmin(res_dist)]\n","\n","  # Load appropriate delivery set\n","  percent_max_dist = min_perc\n","  deliveries_temp = DeliveryList.load_deliveries(\n","    DeliveryList.gen_deliveries_id(distance_based=distance_based, load=load,\n","      hours=hours, peaks=peaks, sigma=sigma, percent_max_dist=min_perc), graph=True\n","  )\n","\n","  # Save in main folder\n","  deliveries = deliveries_temp.copy()\n","  DeliveryList.save_deliveries(deliveries, graph=False)\n","\n","\n","  for i in range(len(percs_to_check)):\n","    print(i, end=\"\\t\")\n","  print()\n","\n","  for i in range(len(percs_to_check)):\n","    if (res_dist[i] < base1_dist[i]):\n","      print(\"\", end=\"\\t\")\n","    elif (res_dist[i] == base1_dist[i]):\n","      print(\"\", end=\"\\t\")\n","    else:\n","      print(\"\", end=\"\\t\")\n","  print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yp8_PJzA3IuR"},"outputs":[],"source":["if(check_OMSD):\n","  with open (deliveries_graphing_dir + f\"/sim_results\", 'rb') as fp:\n","    res_dist = pickle.load(fp)\n","\n","  with open (deliveries_graphing_dir + f\"/baseline_results\", 'rb') as fp:\n","    base1_dist = pickle.load(fp)\n","\n","  # Plot for each time step\n","  time = np.linspace(0, 100, len(percs_to_check))\n","\n","  plt.figure(figsize=(10,6))\n","  plt.plot(percs_to_check, res_dist, label='res_dist', color='b')\n","  plt.plot(percs_to_check, base1_dist, label='base1_dist', color='r')\n","\n","  min_perc = percs_to_check[np.argmin(res_dist)]\n","  plt.vlines(x = min_perc, ymin = min(res_dist)-100, ymax = max(res_dist)+100, colors = 'purple', linestyle = ':')\n","  plt.text(x=min_perc+2, y=max(res_dist)-50, s=f'{min_perc}%', fontsize = 14, color='darkred')\n","\n","\n","  # Adding labels and title\n","  #plt.ylim(bottom=0)\n","  plt.xlabel('Minimum Percentage of Max Distance to Allow Order Sharing (%)')\n","  plt.ylabel('Total Distance (kilometers)')\n","  plt.title('Minimum Percentage vs Total Distance for Baseline 1 and Simulation')\n","  plt.legend()\n","  plt.grid(True)\n","\n","  try:\n","    os.mkdir(data_dir + \"/Images\")\n","  except:\n","    print(data_dir + \"/Images\" + \" Already Exists\")\n","\n","  try:\n","    os.mkdir(f'{data_dir}/Images/Data-{min_children}-{superspot_hotspot_ratio}')\n","  except:\n","    print(f'{data_dir}/Images/Data-{min_children}-{superspot_hotspot_ratio}', \"Already Exists\")\n","\n","  plt.savefig(f'{data_dir}/Images/Data-{min_children}-{superspot_hotspot_ratio}/min_perc_viability_graph.png')\n","\n","  plt.show()\n","\n","  print(\"Min:\", min_perc)"]},{"cell_type":"markdown","metadata":{"id":"T6F_nx8q9hHS"},"source":["### Final Simulation"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1746194761140,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"},"user_tz":240},"id":"57lGNkGM9wv0"},"outputs":[],"source":["# If you ran the above code section 'Determine Optimal Minimum...' then this should be the correct value already, do not reinitialize it.\n","#   Otherwise check the spreadsheet and set the value here accordingly.\n","if(not check_OMSD):\n","  percent_max_dist = 29\n","\n","if(single_run):\n","  deliveries = DeliveryList.load_deliveries(\n","    DeliveryList.gen_deliveries_id(distance_based=distance_based, load=load,\n","      hours=hours, peaks=peaks, sigma=sigma, percent_max_dist=percent_max_dist), graph=False\n","  )\n","  deliveries.reset_deliveries()"]},{"cell_type":"code","execution_count":31,"metadata":{"collapsed":true,"executionInfo":{"elapsed":232,"status":"ok","timestamp":1746195726284,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"},"user_tz":240},"id":"Nhyu71-f-CTH"},"outputs":[],"source":["Q_orig = np.load(data_dir + f\"/Q Tables/Data-{min_children}-{superspot_hotspot_ratio}/Q_boltzman.npz\", allow_pickle=True)\n","Q_orig = {int(key): Q_orig[key] for key in Q_orig}\n","\n","if(single_run):\n","  env = Environment(deliverylist=deliveries, num_hotspots=num_hotspots, distance_matrix=full_dist_matrix, time_matrix=full_time_matrix, Q_table=Q_tables, Q_orig=Q_orig)\n","  env.run()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iIlFGP7_-Lsj"},"outputs":[],"source":["if(single_run):\n","  results = env.results()\n","  baseline1 = env.baseline1()\n","  baseline2 = env.baseline2()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7wI76KMX_ymN"},"outputs":[],"source":["def print_results(results, name:str=\"Results\", show_mean=False, show_median=True, show_full=False, show_req_clock=False, show_all=False):\n","  successful_distances = [d[0] for d in results['distances_tagged'] if d[2]]\n","  successful_times = [t[0] for t in results['times_tagged'] if t[2]]\n","\n","  print(name)\n","  print(\"Shares: \", results['shares'])\n","  print(\"success rate: \", results['success_rate'], '%')\n","  print(\"total distance: \", sum(successful_distances)/1000, 'km')\n","  if show_full or show_all:\n","    print(\"total distance (regardless fail): \", sum(results['distances'])/1000, 'km')\n","    print(\"total time (regardless fail): \", sum(results['times']), 's')\n","  if show_mean or show_all:\n","    mean = np.mean(successful_distances)/1000\n","\n","    print(\"mean distance: \", mean, 'km')\n","  if show_median or show_all:\n","    median = np.median(successful_distances)/1000\n","\n","    print(\"median distance: \", median, 'km')\n","  if show_mean or show_all:\n","    mean = np.mean(successful_times)\n","\n","    print(\"mean time: \", mean, 's')\n","  if show_median or show_all:\n","    median = np.median(successful_times)\n","\n","    print(\"median time: \", median, 's')\n","  print(\"Vehicles \", results['CDV'])\n","  print(\"Hops \", results['hops'])\n","  if show_full or show_all:\n","    print(\"Hops (regardless fail): \", results['hops_all'])\n","  print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gAIHcmDb_5-5"},"outputs":[],"source":["if(single_run):\n","  print_results(results, show_all=True)\n","\n","  print_results(baseline1, name=\"Baseline 1\", show_all=True)\n","\n","  print_results(baseline2, name=\"Baseline 2\", show_all=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RlcRLTjV_7zp"},"outputs":[],"source":["def print_dict(d):\n","  for k, v in d.items():\n","    print(f\"{k}: {v*100}%\")\n","  print()\n","\n","if(single_run):\n","  print_dict(results['success_rate_grouped'])\n","  print_dict(baseline1['success_rate_grouped'])\n","  print_dict(baseline2['success_rate_grouped'])"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1746194764969,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"},"user_tz":240},"id":"CoYsW5Fd_9mF"},"outputs":[],"source":["# Create Directories\n","try:\n","  os.mkdir(data_dir + f\"/Results/\")\n","except:\n","  print(data_dir + f\"/Results/\" + \" Already Exists\")\n","\n","try:\n","  os.mkdir(data_dir + f\"/Results/Data-{min_children}-{superspot_hotspot_ratio}/\")\n","except:\n","  print(data_dir + f\"/Results/Data-{min_children}-{superspot_hotspot_ratio}/\" + \" Already Exists\")\n","\n","\n","class NumpyArrayEncoder(json.JSONEncoder):\n","  def default(self, obj):\n","    if isinstance(obj, np.ndarray):\n","        return obj.tolist()\n","    # Check if obj is a NumPy integer and convert to Python int\n","    if isinstance(obj, (np.int64, np.int32, np.int16, np.int8)):\n","        return int(obj)\n","    return json.JSONEncoder.default(self, obj)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dXpD7KeWADIl"},"outputs":[],"source":["if(single_run):\n","  with open(f'{data_dir}/Results/Data-{min_children}-{superspot_hotspot_ratio}/results_{deliveries.id}_{min_children}_{superspot_hotspot_ratio}.json', 'w') as f:\n","    json.dump(results, f, cls=NumpyArrayEncoder)\n","\n","  with open(f'{data_dir}/Results/Data-{min_children}-{superspot_hotspot_ratio}/baseline1_{deliveries.id}_{min_children}_{superspot_hotspot_ratio}.json', 'w') as f:\n","    json.dump(baseline1, f, cls=NumpyArrayEncoder)\n","\n","  with open(f'{data_dir}/Results/Data-{min_children}-{superspot_hotspot_ratio}/baseline2_{deliveries.id}_{min_children}_{superspot_hotspot_ratio}.json', 'w') as f:\n","    json.dump(baseline2, f, cls=NumpyArrayEncoder)"]},{"cell_type":"markdown","metadata":{"id":"PHWreNvMfGN0"},"source":["#### Repeating Simulation"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":277,"status":"ok","timestamp":1746195729940,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"},"user_tz":240},"id":"t0CoAGOsfmfU","outputId":"9cb31baf-6aec-4cd8-d05d-569dad60dc91"},"outputs":[{"output_type":"stream","name":"stdout","text":["./gdrive/MyDrive/DeliverAI Data Folder/City of New York - RL Delivery Data/Results/Data-12-15/Repeating Already Exists\n"]}],"source":["try:\n","  os.mkdir(data_dir + f\"/Results/Data-{min_children}-{superspot_hotspot_ratio}/Repeating\")\n","except:\n","  print(data_dir + f\"/Results/Data-{min_children}-{superspot_hotspot_ratio}/Repeating\" + \" Already Exists\")"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QaW5zMKHfJl4","executionInfo":{"status":"ok","timestamp":1746212893777,"user_tz":240,"elapsed":1250073,"user":{"displayName":"Yusuf Ozdemir","userId":"15419655632086269902"}},"outputId":"00c54736-441b-441d-e1c3-007cf8989d3a"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Loading Order Set 1\n","0-0300-001-010-[0.25, 0.75]-029-01 already exists.\n","Loading from ./gdrive/MyDrive/DeliverAI Data Folder/City of New York - RL Delivery Data/Deliveries/0-0300-001-010-[0.25, 0.75]-029-01\n","Simulating Order Set 1\n","Loading Order Set 2\n","0-0300-001-010-[0.25, 0.75]-029-02 already exists.\n","Loading from ./gdrive/MyDrive/DeliverAI Data Folder/City of New York - RL Delivery Data/Deliveries/0-0300-001-010-[0.25, 0.75]-029-02\n","Simulating Order Set 2\n","Loading Order Set 3\n","0-0300-001-010-[0.25, 0.75]-029-03 already exists.\n","Loading from ./gdrive/MyDrive/DeliverAI Data Folder/City of New York - RL Delivery Data/Deliveries/0-0300-001-010-[0.25, 0.75]-029-03\n","Simulating Order Set 3\n","Loading Order Set 4\n","0-0300-001-010-[0.25, 0.75]-029-04 already exists.\n","Loading from ./gdrive/MyDrive/DeliverAI Data Folder/City of New York - RL Delivery Data/Deliveries/0-0300-001-010-[0.25, 0.75]-029-04\n","Simulating Order Set 4\n","Loading Order Set 5\n","0-0300-001-010-[0.25, 0.75]-029-05 already exists.\n","Loading from ./gdrive/MyDrive/DeliverAI Data Folder/City of New York - RL Delivery Data/Deliveries/0-0300-001-010-[0.25, 0.75]-029-05\n","Simulating Order Set 5\n","Loading Order Set 6\n","0-0300-001-010-[0.25, 0.75]-029-06 already exists.\n","Loading from ./gdrive/MyDrive/DeliverAI Data Folder/City of New York - RL Delivery Data/Deliveries/0-0300-001-010-[0.25, 0.75]-029-06\n","Simulating Order Set 6\n","Loading Order Set 7\n","0-0300-001-010-[0.25, 0.75]-029-07 already exists.\n","Loading from ./gdrive/MyDrive/DeliverAI Data Folder/City of New York - RL Delivery Data/Deliveries/0-0300-001-010-[0.25, 0.75]-029-07\n","Simulating Order Set 7\n","Loading Order Set 8\n","0-0300-001-010-[0.25, 0.75]-029-08 already exists.\n","Loading from ./gdrive/MyDrive/DeliverAI Data Folder/City of New York - RL Delivery Data/Deliveries/0-0300-001-010-[0.25, 0.75]-029-08\n","Simulating Order Set 8\n","Loading Order Set 9\n","0-0300-001-010-[0.25, 0.75]-029-09 already exists.\n","Loading from ./gdrive/MyDrive/DeliverAI Data Folder/City of New York - RL Delivery Data/Deliveries/0-0300-001-010-[0.25, 0.75]-029-09\n","Simulating Order Set 9\n","Loading Order Set 10\n","0-0300-001-010-[0.25, 0.75]-029-10 already exists.\n","Loading from ./gdrive/MyDrive/DeliverAI Data Folder/City of New York - RL Delivery Data/Deliveries/0-0300-001-010-[0.25, 0.75]-029-10\n","Simulating Order Set 10\n"]}],"source":["iter = 10  # How many iterations of unique delivery sets and results to generate\n","already_existing = 10  # Specify how many DELIVERY SETS already exist so you don't have to regenerate them (set to 0 if none generated yet)\n","already_existing_results = 9  # Specify how many RESULTS already exist so you don't have to regenerate them (set to 0 if none generated yet)\n","\n","\n","# Loop over iter...\n","for i in range(iter):\n","  if i < already_existing:  # If delivery set already existing:\n","    if i >= already_existing_results:\n","      print(\"Loading Order Set \" + str(i+1))\n","      # Get the ID\n","      multi_id = DeliveryList.gen_deliveries_id(distance_based=distance_based, load=load,\n","        hours=hours, peaks=peaks, sigma=sigma, percent_max_dist=percent_max_dist, gen_multi=True, multi_id=i+1)\n","      print(multi_id, \"already exists.\")\n","\n","      # Load the deliveries based on ID\n","      multi_delivs = DeliveryList.load_deliveries(multi_id)\n","      multi_delivs.reset_deliveries()\n","    else:\n","      print(\"Skipping Order Set \" + str(i+1))\n","  else:\n","    print(\"Generating Order Set \" + str(i+1))\n","    # Otherwise create the new set of deliveries\n","    multi_delivs = DeliveryList(distance_based=distance_based, load=load, hours=hours, peaks=peaks, sigma=sigma, percent_max_dist=percent_max_dist, gen_multi=True)\n","    multi_delivs.reset_deliveries()\n","\n","\n","  # Run the environment on the delivery set\n","  if i >= already_existing_results:  # If results not already existing:\n","    print(\"Simulating Order Set \" + str(i+1))\n","    multi_env = Environment(deliverylist=multi_delivs, num_hotspots=num_hotspots, distance_matrix=full_dist_matrix, time_matrix=full_time_matrix, Q_table=Q_tables, Q_orig=Q_orig)\n","    multi_env.run()\n","\n","    # Get all relevant results and baselines\n","    multi_results = multi_env.results()\n","    multi_baseline1 = multi_env.baseline1()\n","    multi_baseline2 = multi_env.baseline2()\n","\n","    # Save results in /Repeating directory\n","    with open(f'{data_dir}/Results/Data-{min_children}-{superspot_hotspot_ratio}/Repeating/results_{multi_delivs.id}_{min_children}_{superspot_hotspot_ratio}_{i}.json', 'w') as f:\n","      json.dump(multi_results, f, cls=NumpyArrayEncoder)\n","\n","    with open(f'{data_dir}/Results/Data-{min_children}-{superspot_hotspot_ratio}/Repeating/baseline1_{multi_delivs.id}_{min_children}_{superspot_hotspot_ratio}_{i}.json', 'w') as f:\n","      json.dump(multi_baseline1, f, cls=NumpyArrayEncoder)\n","\n","    with open(f'{data_dir}/Results/Data-{min_children}-{superspot_hotspot_ratio}/Repeating/baseline2_{multi_delivs.id}_{min_children}_{superspot_hotspot_ratio}_{i}.json', 'w') as f:\n","        json.dump(multi_baseline2, f, cls=NumpyArrayEncoder)\n"]}],"metadata":{"colab":{"collapsed_sections":["boK7DL5n3PIB","sMczv4MS3TMr","bE4XTWod3ZU6","Sq2cgAse3him","4ETwlC0U31_M","ZeHtsJvN3_yK","923vw6At4F8Y","RfpLA6Mkwywg","-5OMr08y0aiP"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}